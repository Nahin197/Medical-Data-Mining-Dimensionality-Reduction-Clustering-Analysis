# Medical Data Mining: Dimensionality Reduction & Clustering Analysis

This project performs a comprehensive benchmarking of unsupervised learning techniques on four distinct medical datasets. The core objective is to evaluate how different **Dimensionality Reduction (DR)** embeddings affect the performance of various **Clustering Algorithms** in uncovering hidden patterns within healthcare data.

## ðŸ“‚ Datasets

The analysis is performed on the following datasets, located in the `dataset/` directory:

1.  **Diabetes** (`diabetes.csv`)
    *   **Source**: Pima Indians Diabetes Database.
    *   **Features**: Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI, DiabetesPedigreeFunction, Age.
    *   **Target**: Outcome (0/1).
2.  **Heart Disease** (`heart.csv`)
    *   **Source**: UCI Heart Disease Data.
    *   **Features**: Age, Sex, CP, Trestbps, Chol, FBS, Restecg, Thalach, Exang, Oldpeak, Slope, CA, Thal.
    *   **Target**: Target (0/1).
3.  **Hepatitis** (`hepatitis.data`)
    *   **Source**: UCI Hepatitis Data.
    *   **Features**: 19 attributes including Bilirubin, Albumin, Protime, Histology, etc.
    *   **Target**: Class (LIVE/DIE).
4.  **Kidney Disease** (`kidney_disease.csv`)
    *   **Source**: Chronic Kidney Disease Dataset.
    *   **Features**: 24 attributes (14 numeric, 10 categorical) such as rbc, pc, pcc, ba, htn, etc.
    *   **Target**: Classification (ckd/notckd).

## ðŸ”¬ Methodology

Each dataset undergoes a rigorous pipeline implemented in Jupyter Notebooks:

### 1. Preprocessing
To ensure robust analysis, the code handles real-world data challenges:
*   **Missing Value Imputation**: Using median strategies for numerical data and mode for categorical data.
*   **Cleaning**: Resolving inconsistencies (e.g., non-numeric tokens like "?", whitespace stripping).
*   **Encoding**: Applying One-Hot Encoding to categorical variables.
*   **Scaling**: Standardizing features using `StandardScaler` to ensure distance-based algorithms work correctly.

### 2. Dimensionality Reduction (DR)
We benchmark clustering performance across multiple embedding spaces:
*   **None**: Clustering on raw (scaled) features.
*   **PCA**: Principal Component Analysis (linear projection).
*   **t-SNE**: t-Distributed Stochastic Neighbor Embedding (non-linear).
*   **UMAP**: Uniform Manifold Approximation and Projection (preserves global structure better than t-SNE).

### 3. Clustering Algorithms
We systematically test combinations of:
*   **K-Means**: Centroid-based clustering.
*   **Hierarchical**: Agglomerative clustering.
*   **DBSCAN**: Density-based spatial clustering of applications with noise.
*   **HDBSCAN**: Hierarchical Density-Based Clustering (specifically applied in the Hepatitis study).

### 4. Evaluation Metrics
Cluster quality is quantified using:
*   **Silhouette Score** (Higher is better): Measures cohesion and separation.
*   **Davies-Bouldin Index (DBI)** (Lower is better): Ratio of intra-cluster to inter-cluster distances.
*   **Calinski-Harabasz Index (CHI)** (Higher is better): Ratio of dispersion.

## ðŸ“Š Key Experiments

### Benchmarking (All Notebooks)
Every notebook generates a benchmark table ranking all `DR Method` $\times$ `Clustering Algo` combinations.
*   *Example Finding*: t-SNE often produces the highest Silhouette scores but can fragment continuous manifolds. UMAP frequently offers a balanced representation for density-based clustering.

### Supervised Augmentation
 we go a step further:
*   **Method**: We use the cluster labels generated by the unsupervised pipeline as *new features* for supervised classification.
*   **Models**: Logistic Regression, Random Forest, XGBoost.
*   **Goal**: To determine if unsupervised cluster features provide "leakage-free" signal that improves prediction of patient mortality.

## ðŸš€ Getting Started

### Prerequisites
The project uses Python 3 and requires the following libraries:
```bash
pip install numpy pandas matplotlib seaborn scikit-learn umap-learn xgboost hdbscan
```

### Running the Analysis
The code is organized into four standalone Jupyter notebooks:
1.  **Diabetes**: `code/Diabetes.ipynb`
2.  **Heart Disease**: `code/Heart.ipynb`
3.  **Hepatitis**: `code/Hepatytis.ipynb`
4.  **Kidney Disease**: `code/kidney.ipynb`

To reproduce the results, simply open a notebook and select "Run All".

> **Note**: For `Heart.ipynb` and `Diabetes.ipynb`, ensure the data paths point to the correct location of the CSV files if not running in the default environment.


